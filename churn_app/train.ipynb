{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b160a91",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install xgboost imbalanced-learn shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecfad45",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, f1_score\n",
    "import shap\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b08535",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Step 2: Load and Clean Data\n",
    "df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "df = df[df['TotalCharges'] != ' ']\n",
    "df['TotalCharges'] = df['TotalCharges'].astype(float)\n",
    "df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e3c572",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "def add_features(df):\n",
    "    df = df.copy()\n",
    "    df['AvgChargesPerMonth'] = df['TotalCharges'] / df['tenure']\n",
    "    df['hasStreaming'] = df[['StreamingTV', 'StreamingMovies']].apply(lambda x: int('Yes' in x.values), axis=1)\n",
    "    df['ServiceCount'] = df[['PhoneService', 'MultipleLines', 'OnlineSecurity', 'OnlineBackup',\n",
    "                             'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']].apply(lambda x: list(x).count('Yes'), axis=1)\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12746b02",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Step 4: Define Features and Target\n",
    "X = df.drop(columns=['Churn', 'customerID'])\n",
    "y = df['Churn']\n",
    "\n",
    "# Step 5: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeb4da5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 6: Preprocessing Pipeline\n",
    "num_cols = ['tenure', 'MonthlyCharges', 'TotalCharges', 'AvgChargesPerMonth', 'ServiceCount']\n",
    "cat_cols = [col for col in X.columns if col not in num_cols]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), num_cols),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "])\n",
    "\n",
    "# Step 7: Define Base Models\n",
    "xgb = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    scale_pos_weight=y_train.value_counts()[0] / y_train.value_counts()[1],\n",
    "    eval_metric='logloss',\n",
    "\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1098a426",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Step 8: Stacking Classifier\n",
    "base_learners = [\n",
    "    ('xgb', xgb),\n",
    "    ('lr', log_reg),\n",
    "    ('rf', rf)\n",
    "]\n",
    "\n",
    "stack_model = StackingClassifier(\n",
    "    estimators=base_learners,\n",
    "    final_estimator=LogisticRegression(),\n",
    "    passthrough=True,\n",
    "    cv=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750861a1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from ml_utils import add_features\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline  # if not already imported\n",
    "\n",
    "# Step 2: Define feature engineering transformer\n",
    "feature_engineering = FunctionTransformer(add_features, validate=False)\n",
    "\n",
    "# Step 3: Recreate your pipeline using the imported function\n",
    "pipeline = ImbPipeline(steps=[\n",
    "    ('feature_engineering', feature_engineering),\n",
    "    ('preprocessing', preprocessor),   # your existing preprocessor\n",
    "    ('resample', SMOTETomek(random_state=42)),  # optional, if used\n",
    "    ('classifier', stack_model)\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "# Step 11: Evaluation\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_proba = pipeline.predict_proba(X_test)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d97e9fd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65150175",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming y_test and y_proba are available\n",
    "thresholds = np.arange(0.1, 0.9, 0.05)\n",
    "scores = [(t, f1_score(y_test, (y_proba > t).astype(int))) for t in thresholds]\n",
    "best_thresh = max(scores, key=lambda x: x[1])[0]\n",
    "print(f\"Best threshold for F1-score: {best_thresh}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bd999b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def predict_churn(new_customer_df, threshold=0.5):\n",
    "    customer_id = new_customer_df['customerID'].values[0]\n",
    "    input_df = new_customer_df.drop(columns=['customerID'])\n",
    "\n",
    "    # Let the full pipeline handle feature engineering and preprocessing\n",
    "    prob = pipeline.predict_proba(input_df)[0][1]\n",
    "    pred = int(prob > threshold)\n",
    "\n",
    "    print(f\"CustomerID: {customer_id}\")\n",
    "    print(f\"Predicted Churn: {'Yes' if pred else 'No'}\")\n",
    "    print(f\"Churn Probability: {prob:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d51e81",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "customer_no_churn = pd.DataFrame([{\n",
    "  \"customerID\": \"8888-CHURN\",\n",
    "  \"gender\": \"Female\",\n",
    "  \"SeniorCitizen\": 1,\n",
    "  \"Partner\": \"No\",\n",
    "  \"Dependents\": \"No\",\n",
    "  \"tenure\": 1,\n",
    "  \"PhoneService\": \"Yes\",\n",
    "  \"MultipleLines\": \"No\",\n",
    "  \"InternetService\": \"Fiber optic\",\n",
    "  \"OnlineSecurity\": \"No\",\n",
    "  \"OnlineBackup\": \"No\",\n",
    "  \"DeviceProtection\": \"No\",\n",
    "  \"TechSupport\": \"No\",\n",
    "  \"StreamingTV\": \"No\",\n",
    "  \"StreamingMovies\": \"No\",\n",
    "  \"Contract\": \"Month-to-month\",\n",
    "  \"PaperlessBilling\": \"Yes\",\n",
    "  \"PaymentMethod\": \"Electronic check\",\n",
    "  \"MonthlyCharges\": 95.0,\n",
    "  \"TotalCharges\": 95.0\n",
    "}])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fa7125",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "predict_churn(customer_no_churn )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bba6fc7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile ml_utils.py\n",
    "def add_features(df):\n",
    "    df = df.copy()\n",
    "    df['AvgChargesPerMonth'] = df['TotalCharges'] / df['tenure']\n",
    "    df['hasStreaming'] = df[['StreamingTV', 'StreamingMovies']].apply(lambda x: int('Yes' in x.values), axis=1)\n",
    "    df['ServiceCount'] = df[['PhoneService', 'MultipleLines', 'OnlineSecurity', 'OnlineBackup',\n",
    "                             'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']].apply(lambda x: list(x).count('Yes'), axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e2d166",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from ml_utils import add_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b00957",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import joblib\n",
    "joblib.dump(pipeline, 'churn_model.pkl')  # Save with imported add_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fcbaba",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip freeze > colab_requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae40693",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(\"colab_requirements.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6376971",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pip freeze > requirements.txt\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
